{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data and creating the TF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = open('20news-bydate/vocabulary.txt', 'r').read().split()\n",
    "Y_train = np.array(list(map(int, open('20news-bydate/matlab/train.label', 'r').read().split()))) - 1\n",
    "Y_test = np.array(list(map(int, open('20news-bydate/matlab/test.label', 'r').read().split()))) - 1\n",
    "m_train = len(Y_train)\n",
    "m_test = len(Y_test)\n",
    "LEN_VOCAB = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('20news-bydate/matlab/train.data', sep=' ', header=None, names=['doc', 'word', 'count'])\n",
    "X_test = pd.read_csv('20news-bydate/matlab/test.data', sep=' ', header=None, names=['doc', 'word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.groupby('doc').apply(lambda x: dict(zip(x['word'], x['count'])))\n",
    "X_test = X_test.groupby('doc').apply(lambda x: dict(zip(x['word'], x['count'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dic_to_array(dic):\n",
    "    ar = np.zeros(LEN_VOCAB)\n",
    "    for i, j in dic.items():\n",
    "        ar[i-1] = j\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=61188, out_features=100)\n",
      "  (fc2): Linear(in_features=100, out_features=20)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=LEN_VOCAB, output_size=20, hidden_layer_size=100):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_layer_size, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, output_size, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def random_mini_batches_idx(m, mini_batch_size = 64, seed = 0):\n",
    "    permutation = np.random.permutation(m)\n",
    "    num_complete_minibatches = int(math.floor(m/mini_batch_size)) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    list_of_indices = []\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        list_of_indices.append(list(permutation[k * mini_batch_size: k * mini_batch_size + mini_batch_size]))\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        list_of_indices.append(list(permutation[num_complete_minibatches * mini_batch_size : m]))\n",
    "    return list_of_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.04614428964415654\n",
      "Accuracy on test set: 0.05116588940706196\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(X, Y):\n",
    "    minibatches_indices = random_mini_batches_idx(len(X), mini_batch_size=10)\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "    for i, indices in enumerate(minibatches_indices):\n",
    "        # get the inputs\n",
    "        X_minibatch = X.iloc[indices]\n",
    "        inputs = np.vstack(X_minibatch.apply(from_dic_to_array).tolist())\n",
    "        labels = Y[indices]\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        true_labels = torch.from_numpy(labels).long()\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(true_labels)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_correct += (predicted == true_labels).sum()\n",
    "        total_examples += len(indices)\n",
    "    return float(total_correct)/total_examples\n",
    "print (\"Accuracy on training set: {0}\".format(get_accuracy(X_train, Y_train)))\n",
    "print (\"Accuracy on test set: {0}\".format(get_accuracy(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs=3, lr=0.01, momentum=.9, mini_batch_size=8, seed=0):\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    accuracies_train = []\n",
    "    accuracies_train2 = [get_accuracy(X_train, Y_train)]\n",
    "    accuracies_test = [get_accuracy(X_test, Y_test)]\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        minibatches_indices = random_mini_batches_idx(m_train, mini_batch_size=mini_batch_size, seed=seed)\n",
    "        running_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        for i, indices in enumerate(minibatches_indices):\n",
    "            # get the inputs\n",
    "            X_minibatch = X_train.iloc[indices]\n",
    "            inputs = np.vstack(X_minibatch.apply(from_dic_to_array).tolist())\n",
    "            labels = Y_train[indices]\n",
    "            inputs = torch.from_numpy(inputs).float()\n",
    "            true_labels = torch.from_numpy(labels).long()\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs), Variable(true_labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #evaluate accuracy on train set\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == true_labels).sum()\n",
    "            total_examples += len(indices)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 700 == 699:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.4f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "        accuracies_train.append(total_correct/float(total_examples))\n",
    "        accuracies_train2.append(get_accuracy(X_train, Y_train))\n",
    "        accuracies_test.append(get_accuracy(X_test, Y_test))\n",
    "    print('Finished Training')\n",
    "    return accuracies_train, accuracies_train2, accuracies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   700] loss: 0.9812\n",
      "[1,  1400] loss: 0.9175\n",
      "[2,   700] loss: 0.8710\n",
      "[2,  1400] loss: 0.8654\n",
      "[3,   700] loss: 0.8458\n",
      "[3,  1400] loss: 0.8278\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "accuracies_train, accuracies_train2, accuracies_test = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
