{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on python 3.6\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters per layer:[401920, 131328, 2570] and total: 535818\n"
     ]
    }
   ],
   "source": [
    "h = [784,512,256,10]\n",
    "# Don't forget the bias in the count\n",
    "nb_params = [(h[i]+1)*h[i+1] for i in range(len(h)-1)]\n",
    "total_params = sum(nb_params)\n",
    "print(\"Number of parameters per layer:{} and total: {}\".format(nb_params,total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    \n",
    "    def __init__(self,sizes):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(sizes)-2):\n",
    "            layers.append(nn.Linear(sizes[i],sizes[i+1],bias=True))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(sizes[-2],sizes[-1],bias=True))\n",
    "        \n",
    "        self.predict_ = nn.Sequential(*layers)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784)\n",
    "        return self.predict_(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return nn.Softmax(dim=1)(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return torch.max(self.predict_proba(x),1)[1]\n",
    "    \n",
    "    def loss(self, x, target):\n",
    "        proba = self(x)\n",
    "        return self.criterion(proba, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MultiLayerPerceptron(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=512)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=256)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "        self.batch_size = 32\n",
    "        self.test_batch_size = 5\n",
    "        self.learning_rate = .01\n",
    "        self.momentum=0\n",
    "        self.log_interval = 500\n",
    "        self.epochs=10\n",
    "    \n",
    "args = Args()\n",
    "kwargs  = {}\n",
    "if args.cuda:\n",
    "    mlp.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(mlp.parameters(), lr=args.learning_rate, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def data_loaders(args):\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "    download_loc = \"/Tmp/lepriolr/\"\n",
    "    mnist_train = datasets.MNIST(download_loc, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                       ]))\n",
    "\n",
    "    mnist_test = datasets.MNIST(download_loc, train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "    nb_train = 50000\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "            mnist_train, \n",
    "            sampler=SubsetRandomSampler(np.arange(nb_train)),\n",
    "            batch_size=args.batch_size, **kwargs)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "            mnist_train, \n",
    "            sampler=SubsetRandomSampler(np.arange(nb_train,len(mnist_train))),\n",
    "            batch_size=args.batch_size, **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(mnist_test,\n",
    "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "train_loader,valid_loader,test_loader = data_loaders(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mlp, optimizer, epoch_idx,printing=True):\n",
    "    ans= []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        loss = mlp.loss(data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            if printing:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch_idx, batch_idx * train_loader.batch_size, len(train_loader.sampler),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "            ans.append((batch_idx * train_loader.batch_size+ epoch_idx*len(train_loader.sampler), loss.data[0]))\n",
    "\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.318316\n",
      "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 0.398803\n",
      "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 0.366071\n",
      "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 0.443953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2.3183164596557617),\n",
       " (16000, 0.39880305528640747),\n",
       " (32000, 0.3660711646080017),\n",
       " (48000, 0.4439525008201599)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(mlp, optimizer, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(mlp, loader):\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = mlp(data)\n",
    "        valid_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = mlp.predict(output)\n",
    "        correct += pred.data.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(loader.dataset)\n",
    "    accuracy = correct / len(loader.sampler)\n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        valid_loss, correct, len(loader.sampler),\n",
    "        100. * accuracy))\n",
    "    \n",
    "    return valid_loss,accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation set: Average loss: 0.2384, Accuracy: 45820/50000 (92%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2384420830051104, 0.9164)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_loss.extend(train(epoch))\n",
    "    valid_loss.append(validation(valid_loader))\n",
    "end = time.time()\n",
    "np.floor((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below m stands for module\n",
    "# this functon is applied recursively to all the sub-modules of a neural network\n",
    "def init_zero(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant(m.weight,0)\n",
    "        nn.init.constant(m.bias,0)\n",
    "\n",
    "        \n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal(m.weight,mean=0,std=1)\n",
    "        nn.init.constant(m.bias,0)\n",
    "        \n",
    "        \n",
    "def init_glorot(m):\n",
    "    gain = nn.init.calculate_gain('relu')\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform(m.weight,gain=gain)\n",
    "        nn.init.constant(m.bias,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.apply(init_glorot)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.302585\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.299696\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.295147\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.297716\n",
      "\n",
      " Validation set: Average loss: 1.9176, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.301996\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.314201\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.309832\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 2.307774\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.312147\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 2.301348\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 2.296131\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 2.288685\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.315754\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 2.293621\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 2.316525\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.308353\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 2.287703\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 2.328834\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 2.296524\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 2.269829\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 2.303771\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 2.304494\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 2.295299\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 2.294543\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.297779\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 2.296777\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 2.295423\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 2.312109\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 2.301691\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 2.305181\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 2.312052\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 2.320029\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 2.278991\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 2.303227\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 2.291536\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 2.315846\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 2.295407\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 2.299898\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 2.308467\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 2.292214\n",
      "\n",
      " Validation set: Average loss: 1.9175, Accuracy: 5678/50000 (11%)\n",
      "\n",
      "[1.917581690533956, 1.917519043858846, 1.9175257266998291, 1.9175161018371583, 1.9175215052286785, 1.9175138882319132, 1.9175169046401979, 1.9175174021402994, 1.9175286925633748, 1.91752018699646]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(mlp, optimizer, epoch, printing=True)\n",
    "    train_loss.append(mlp, validation(train_loader)[0])\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00, 1.92e+00\n"
     ]
    }
   ],
   "source": [
    "print(', '.join('{:.2e}'.format(k) for k in train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_loss = train_loss\n",
    "#normal_loss = train_loss\n",
    "#glorot_loss = train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/compare_init.npy\",[zero_loss,normal_loss,glorot_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a20fba2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis = np.arange(1,11)\n",
    "plt.plot(xaxis, zero_loss,label='zero')\n",
    "plt.plot(xaxis, normal_loss, label='normal')\n",
    "plt.plot(xaxis, glorot_loss, label='glorot')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.title(\"Comparison of initialization schemes\")\n",
    "plt.savefig(\"results/compare_init.pdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for son in mlp.children():\n",
    "    for sonn in son.children():\n",
    "        if type(sonn)==nn.Linear:\n",
    "            print(sonn.bias.data)\n",
    "            print(sonn.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation set: Average loss: 4.2775, Accuracy: 4214/50000 (8%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.8445, Accuracy: 806/10000 (8%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.apply(init_glorot)\n",
    "results = []\n",
    "results.append(validation(mlp, train_loader))\n",
    "results.append(validation(mlp, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "\n",
      " Validation set: Average loss: 0.1292, Accuracy: 47689/50000 (95%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0283, Accuracy: 9514/10000 (95%)\n",
      "\n",
      "Epoch  1\n",
      "\n",
      " Validation set: Average loss: 0.0804, Accuracy: 48666/50000 (97%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0220, Accuracy: 9634/10000 (96%)\n",
      "\n",
      "Epoch  2\n",
      "\n",
      " Validation set: Average loss: 0.0623, Accuracy: 49010/50000 (98%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0196, Accuracy: 9666/10000 (97%)\n",
      "\n",
      "Epoch  3\n",
      "\n",
      " Validation set: Average loss: 0.0459, Accuracy: 49322/50000 (99%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0176, Accuracy: 9713/10000 (97%)\n",
      "\n",
      "Epoch  4\n",
      "\n",
      " Validation set: Average loss: 0.0394, Accuracy: 49431/50000 (99%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "Epoch  5\n",
      "\n",
      " Validation set: Average loss: 0.0306, Accuracy: 49625/50000 (99%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0164, Accuracy: 9722/10000 (97%)\n",
      "\n",
      "Epoch  6\n",
      "\n",
      " Validation set: Average loss: 0.0241, Accuracy: 49725/50000 (99%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0155, Accuracy: 9722/10000 (97%)\n",
      "\n",
      "Epoch  7\n",
      "\n",
      " Validation set: Average loss: 0.0208, Accuracy: 49787/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0154, Accuracy: 9745/10000 (97%)\n",
      "\n",
      "Epoch  8\n",
      "\n",
      " Validation set: Average loss: 0.0177, Accuracy: 49810/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0157, Accuracy: 9746/10000 (97%)\n",
      "\n",
      "Epoch  9\n",
      "\n",
      " Validation set: Average loss: 0.0133, Accuracy: 49909/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0150, Accuracy: 9756/10000 (98%)\n",
      "\n",
      "Epoch  10\n",
      "\n",
      " Validation set: Average loss: 0.0114, Accuracy: 49941/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0147, Accuracy: 9761/10000 (98%)\n",
      "\n",
      "Epoch  11\n",
      "\n",
      " Validation set: Average loss: 0.0134, Accuracy: 49862/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0156, Accuracy: 9738/10000 (97%)\n",
      "\n",
      "Epoch  12\n",
      "\n",
      " Validation set: Average loss: 0.0086, Accuracy: 49982/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0147, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Epoch  13\n",
      "\n",
      " Validation set: Average loss: 0.0071, Accuracy: 49986/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0147, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Epoch  14\n",
      "\n",
      " Validation set: Average loss: 0.0068, Accuracy: 49984/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0147, Accuracy: 9766/10000 (98%)\n",
      "\n",
      "Epoch  15\n",
      "\n",
      " Validation set: Average loss: 0.0068, Accuracy: 49983/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0149, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Epoch  16\n",
      "\n",
      " Validation set: Average loss: 0.0054, Accuracy: 49995/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0147, Accuracy: 9775/10000 (98%)\n",
      "\n",
      "Epoch  17\n",
      "\n",
      " Validation set: Average loss: 0.0047, Accuracy: 49996/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0149, Accuracy: 9776/10000 (98%)\n",
      "\n",
      "Epoch  18\n",
      "\n",
      " Validation set: Average loss: 0.0044, Accuracy: 49999/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0148, Accuracy: 9770/10000 (98%)\n",
      "\n",
      "Epoch  19\n",
      "\n",
      " Validation set: Average loss: 0.0039, Accuracy: 49998/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0147, Accuracy: 9775/10000 (98%)\n",
      "\n",
      "Epoch  20\n",
      "\n",
      " Validation set: Average loss: 0.0036, Accuracy: 49998/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0149, Accuracy: 9774/10000 (98%)\n",
      "\n",
      "Epoch  21\n",
      "\n",
      " Validation set: Average loss: 0.0033, Accuracy: 49999/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0148, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Epoch  22\n",
      "\n",
      " Validation set: Average loss: 0.0032, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0149, Accuracy: 9781/10000 (98%)\n",
      "\n",
      "Epoch  23\n",
      "\n",
      " Validation set: Average loss: 0.0028, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0151, Accuracy: 9781/10000 (98%)\n",
      "\n",
      "Epoch  24\n",
      "\n",
      " Validation set: Average loss: 0.0028, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0152, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Epoch  25\n",
      "\n",
      " Validation set: Average loss: 0.0025, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0151, Accuracy: 9775/10000 (98%)\n",
      "\n",
      "Epoch  26\n",
      "\n",
      " Validation set: Average loss: 0.0024, Accuracy: 49999/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0152, Accuracy: 9777/10000 (98%)\n",
      "\n",
      "Epoch  27\n",
      "\n",
      " Validation set: Average loss: 0.0023, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0152, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Epoch  28\n",
      "\n",
      " Validation set: Average loss: 0.0021, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0152, Accuracy: 9782/10000 (98%)\n",
      "\n",
      "Epoch  29\n",
      "\n",
      " Validation set: Average loss: 0.0020, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0154, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  30\n",
      "\n",
      " Validation set: Average loss: 0.0019, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0154, Accuracy: 9782/10000 (98%)\n",
      "\n",
      "Epoch  31\n",
      "\n",
      " Validation set: Average loss: 0.0019, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0154, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  32\n",
      "\n",
      " Validation set: Average loss: 0.0018, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0154, Accuracy: 9778/10000 (98%)\n",
      "\n",
      "Epoch  33\n",
      "\n",
      " Validation set: Average loss: 0.0017, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0155, Accuracy: 9782/10000 (98%)\n",
      "\n",
      "Epoch  34\n",
      "\n",
      " Validation set: Average loss: 0.0016, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0155, Accuracy: 9781/10000 (98%)\n",
      "\n",
      "Epoch  35\n",
      "\n",
      " Validation set: Average loss: 0.0016, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0155, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  36\n",
      "\n",
      " Validation set: Average loss: 0.0015, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0156, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  37\n",
      "\n",
      " Validation set: Average loss: 0.0014, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0156, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  38\n",
      "\n",
      " Validation set: Average loss: 0.0014, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0157, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Epoch  39\n",
      "\n",
      " Validation set: Average loss: 0.0013, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0157, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Epoch  40\n",
      "\n",
      " Validation set: Average loss: 0.0013, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0158, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  41\n",
      "\n",
      " Validation set: Average loss: 0.0013, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0158, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  42\n",
      "\n",
      " Validation set: Average loss: 0.0012, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0158, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  43\n",
      "\n",
      " Validation set: Average loss: 0.0012, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0159, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Epoch  44\n",
      "\n",
      " Validation set: Average loss: 0.0011, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0158, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  45\n",
      "\n",
      " Validation set: Average loss: 0.0011, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0159, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  46\n",
      "\n",
      " Validation set: Average loss: 0.0011, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0159, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  47\n",
      "\n",
      " Validation set: Average loss: 0.0010, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0159, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  48\n",
      "\n",
      " Validation set: Average loss: 0.0010, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0160, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  49\n",
      "\n",
      " Validation set: Average loss: 0.0010, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0160, Accuracy: 9784/10000 (98%)\n",
      "\n",
      "Epoch  50\n",
      "\n",
      " Validation set: Average loss: 0.0010, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0161, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  51\n",
      "\n",
      " Validation set: Average loss: 0.0009, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0162, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  52\n",
      "\n",
      " Validation set: Average loss: 0.0009, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0162, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  53\n",
      "\n",
      " Validation set: Average loss: 0.0009, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0161, Accuracy: 9782/10000 (98%)\n",
      "\n",
      "Epoch  54\n",
      "\n",
      " Validation set: Average loss: 0.0009, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0161, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Epoch  55\n",
      "\n",
      " Validation set: Average loss: 0.0008, Accuracy: 50000/50000 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation set: Average loss: 0.0162, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Epoch  56\n",
      "\n",
      " Validation set: Average loss: 0.0008, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0162, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  57\n",
      "\n",
      " Validation set: Average loss: 0.0008, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0163, Accuracy: 9781/10000 (98%)\n",
      "\n",
      "Epoch  58\n",
      "\n",
      " Validation set: Average loss: 0.0008, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0163, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  59\n",
      "\n",
      " Validation set: Average loss: 0.0008, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0163, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  60\n",
      "\n",
      " Validation set: Average loss: 0.0008, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0163, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  61\n",
      "\n",
      " Validation set: Average loss: 0.0007, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0164, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  62\n",
      "\n",
      " Validation set: Average loss: 0.0007, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0164, Accuracy: 9790/10000 (98%)\n",
      "\n",
      "Epoch  63\n",
      "\n",
      " Validation set: Average loss: 0.0007, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0164, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  64\n",
      "\n",
      " Validation set: Average loss: 0.0007, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0164, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  65\n",
      "\n",
      " Validation set: Average loss: 0.0007, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0164, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Epoch  66\n",
      "\n",
      " Validation set: Average loss: 0.0007, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0165, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  67\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0165, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  68\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0165, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  69\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0165, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  70\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0166, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  71\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0166, Accuracy: 9784/10000 (98%)\n",
      "\n",
      "Epoch  72\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0166, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  73\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0166, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  74\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0166, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  75\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0167, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  76\n",
      "\n",
      " Validation set: Average loss: 0.0006, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0167, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  77\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0167, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  78\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0168, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  79\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0167, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  80\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0167, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  81\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0167, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  82\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0168, Accuracy: 9784/10000 (98%)\n",
      "\n",
      "Epoch  83\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Epoch  84\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  85\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  86\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  87\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Epoch  88\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9793/10000 (98%)\n",
      "\n",
      "Epoch  89\n",
      "\n",
      " Validation set: Average loss: 0.0005, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0170, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  90\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0170, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Epoch  91\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0169, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Epoch  92\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0170, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Epoch  93\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0170, Accuracy: 9790/10000 (98%)\n",
      "\n",
      "Epoch  94\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0170, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  95\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0170, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  96\n",
      "\n",
      " Validation set: Average loss: 0.0004, Accuracy: 50000/50000 (100%)\n",
      "\n",
      "\n",
      " Validation set: Average loss: 0.0171, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Epoch  97\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 100\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "    train(mlp, optimizer, epoch, printing=False)\n",
    "    results1.append(validation(mlp, train_loader))\n",
    "    results1.append(validation(mlp, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = [j for i,j in  results[::2]]\n",
    "valid_accuracy = [j for i,j in  results[1::2]]\n",
    "print(\"training set :\", train_accuracy)\n",
    "print(\"validation set :\", valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_low = train_accuracy\n",
    "valid_accuracy_low = valid_accuracy \n",
    "#train_accuracy_high = train_accuracy\n",
    "#valid_accuracy_high = valid_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = [784,1024,256,10]\n",
    "mlp1 = MultiLayerPerceptron(h)\n",
    "optimizer1 = optim.SGD(mlp#.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
    "mlp1.apply(init_glorot)\n",
    "results1 = []\n",
    "results1.append(validation(mlp1,train_loader))\n",
    "results1.append(validation(mlp1, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "    train(mlp1, optimizer1, epoch, printing=False)\n",
    "    results1.append(validation(mlp1, train_loader))\n",
    "    results1.append(validation(mlp1, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.arange(args.eporch) \n",
    "plt.plot(xaxis, train_accuracy_low, label=\"train low\")\n",
    "plt.plot(xaxis, valid_accuracy_low, label=\"valid low\")\n",
    "#plt.plot(xaxis, train_accuracy_high, label=\"train high\")\n",
    "#plt.plot(xaxis, train_accuracy_high, label=\"train high\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Generalization performance with high and low capacity models\")\n",
    "plt.savefig(\"results/compare_init.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set size, generalization gap and standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [.01,.02,.05,.1,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch36]",
   "language": "python",
   "name": "conda-env-pytorch36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
